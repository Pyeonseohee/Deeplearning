{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "가천대학교_lesson06_RCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Es_tInvL9jj3",
        "jg9rqN9L_lBr",
        "gQ49ylJ4_sMU",
        "gsBrSPyOPOXQ",
        "ZMd4QgFhSWfF",
        "O5lJeOOFS7G5"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pyeonseohee/Deeplearning/blob/main/%EA%B0%80%EC%B2%9C%EB%8C%80%ED%95%99%EA%B5%90_lesson06_RCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Es_tInvL9jj3"
      },
      "source": [
        "# Region Proposal method "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XoGSAPdTSVJ"
      },
      "source": [
        "Selective Search package installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT8a1aix7SrQ"
      },
      "source": [
        "!pip install selectivesearch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqBUZWzS91sV"
      },
      "source": [
        "Region Proposal by selective search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4QMBdx0MEJn"
      },
      "source": [
        "import skimage.data\r\n",
        "import selectivesearch\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "img = skimage.data.astronaut()\r\n",
        "img_lbl, regions = selectivesearch.selective_search(img, scale=500, sigma=0.9, min_size=10)\r\n",
        "plt.imshow(img)\r\n",
        "plt.show()\r\n",
        "regions[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpfN7HJZ-7ZZ"
      },
      "source": [
        "Changes in regional proposals according to the minimum size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjsxeH8sANPt"
      },
      "source": [
        "import matplotlib.patches as patches\r\n",
        "\r\n",
        "fig = plt.figure(figsize=(30,8))\r\n",
        "\r\n",
        "for i,min_size in enumerate([10000,1000,100,10]):\r\n",
        "  img_lbl, regions = selectivesearch.selective_search(img, scale=500, sigma=0.9, min_size=min_size)\r\n",
        "\r\n",
        "  ax = fig.add_subplot(1,4,i+1)\r\n",
        "  ax.imshow(img)\r\n",
        "  ax.set_title(f'Region Proposal minimum size {min_size}')\r\n",
        "\r\n",
        "  for region in regions:\r\n",
        "    x = region['rect'][0]\r\n",
        "    y = region['rect'][1]\r\n",
        "    w = region['rect'][2] \r\n",
        "    h = region['rect'][3] \r\n",
        "\r\n",
        "    \r\n",
        "    rect = patches.Rectangle((x,y),\r\n",
        "                  w,\r\n",
        "                  h,\r\n",
        "                  linewidth=1,\r\n",
        "                  edgecolor='red',\r\n",
        "                  fill = False)\r\n",
        "    ax.add_patch(rect)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jg9rqN9L_lBr"
      },
      "source": [
        "# RCNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9zCmF7h_pjJ"
      },
      "source": [
        "RCNN gitbub installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnidmnCZ3uZl"
      },
      "source": [
        "!git clone https://github.com/yangxue0827/RCNN.git \r\n",
        "!pip install opencv-python\r\n",
        "!pip install tflearn\r\n",
        "%cd ./RCNN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQ49ylJ4_sMU"
      },
      "source": [
        "# Model pre-training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHe3F5gxTPN-"
      },
      "source": [
        "Visualize pre-training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpSqeNpfX-5M"
      },
      "source": [
        "import skimage\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "fig = plt.figure(figsize=(20,20))\r\n",
        "for i in range(17):\r\n",
        "  filename = f'image_{i*80+1:04}.jpg'\r\n",
        "  img = skimage.io.imread(f'./17flowers/jpg/{i}/{filename}')\r\n",
        "  ax = fig.add_subplot(5,4,i+1)\r\n",
        "  ax.imshow(img)\r\n",
        "  #ax.set_title(f'{filename}           Class:{i}')\r\n",
        "  ax.set_title(f'Class:{i}')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiZJy724MpaC"
      },
      "source": [
        "Architecture design"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmwVTbSeMnBb"
      },
      "source": [
        "from train_alexnet import *\r\n",
        "\r\n",
        "IMAGE_SIZE = [227,227]\r\n",
        "num_classes = 17\r\n",
        "\r\n",
        "# Building 'AlexNet'\r\n",
        "def create_alexnet(num_classes):\r\n",
        "    network = input_data(shape=[None, IMAGE_SIZE[0], IMAGE_SIZE[1], 3])\r\n",
        "    network = conv_2d(network, 96, 11, strides=4, activation='relu')\r\n",
        "    network = max_pool_2d(network, 3, strides=2)\r\n",
        "    network = local_response_normalization(network)\r\n",
        "    network = conv_2d(network, 256, 5, activation='relu')\r\n",
        "    network = max_pool_2d(network, 3, strides=2)\r\n",
        "    network = local_response_normalization(network)\r\n",
        "    network = conv_2d(network, 384, 3, activation='relu')\r\n",
        "    network = conv_2d(network, 384, 3, activation='relu')\r\n",
        "    network = conv_2d(network, 256, 3, activation='relu')\r\n",
        "    network = max_pool_2d(network, 3, strides=2)\r\n",
        "    network = local_response_normalization(network)\r\n",
        "    network = fully_connected(network, 4096, activation='tanh')\r\n",
        "    network = dropout(network, 0.5)\r\n",
        "    network = fully_connected(network, 4096, activation='tanh')\r\n",
        "    network = dropout(network, 0.5)\r\n",
        "    network = fully_connected(network, num_classes, activation='softmax')\r\n",
        "    network = regression(network, optimizer='momentum',\r\n",
        "                         loss='categorical_crossentropy',\r\n",
        "                         learning_rate=0.001)\r\n",
        "    return network\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Q3R96RSAB0I"
      },
      "source": [
        "Model pre-training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH35TaCBWBbI"
      },
      "source": [
        "!python train_alexnet.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzGJzrAD6Ty8",
        "outputId": "2b718961-1f5e-412d-d6f1-c4285a18b563"
      },
      "source": [
        "!python train_alexnet.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-29 02:47:43.927391: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/initializations.py:110: calling UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:538: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/initializations.py:165: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "2021-01-29 02:47:55.022785: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-01-29 02:47:55.061743: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-01-29 02:47:55.168193: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-01-29 02:47:55.168257: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (b432deb01952): /proc/driver/nvidia/version does not exist\n",
            "2021-01-29 02:47:55.168895: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-01-29 02:47:55.594998: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)\n",
            "2021-01-29 02:47:55.628696: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2249995000 Hz\n",
            "2021-01-29 02:47:57.962652: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "---------------------------------\n",
            "Run id: alexnet_oxflowers17\n",
            "Log directory: output/\n",
            "---------------------------------\n",
            "Training samples: 1224\n",
            "Validation samples: 136\n",
            "--\n",
            "Training Step: 1  | time: 19.746s\n",
            "| Momentum | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0064/1224\n",
            "Training Step: 2  | total loss: \u001b[1m\u001b[32m2.92411\u001b[0m\u001b[0m | time: 36.664s\n",
            "| Momentum | epoch: 001 | loss: 2.92411 - acc: 0.0422 -- iter: 0128/1224\n",
            "Training Step: 3  | total loss: \u001b[1m\u001b[32m3.53404\u001b[0m\u001b[0m | time: 53.582s\n",
            "| Momentum | epoch: 001 | loss: 3.53404 - acc: 0.0332 -- iter: 0192/1224\n",
            "Training Step: 4  | total loss: \u001b[1m\u001b[32m3.51035\u001b[0m\u001b[0m | time: 70.662s\n",
            "| Momentum | epoch: 001 | loss: 3.51035 - acc: 0.0669 -- iter: 0256/1224\n",
            "Training Step: 5  | total loss: \u001b[1m\u001b[32m3.38565\u001b[0m\u001b[0m | time: 87.754s\n",
            "| Momentum | epoch: 001 | loss: 3.38565 - acc: 0.0855 -- iter: 0320/1224\n",
            "Training Step: 6  | total loss: \u001b[1m\u001b[32m3.23231\u001b[0m\u001b[0m | time: 104.552s\n",
            "| Momentum | epoch: 001 | loss: 3.23231 - acc: 0.0908 -- iter: 0384/1224\n",
            "Training Step: 7  | total loss: \u001b[1m\u001b[32m3.31386\u001b[0m\u001b[0m | time: 121.382s\n",
            "| Momentum | epoch: 001 | loss: 3.31386 - acc: 0.0738 -- iter: 0448/1224\n",
            "Training Step: 8  | total loss: \u001b[1m\u001b[32m3.35118\u001b[0m\u001b[0m | time: 138.000s\n",
            "| Momentum | epoch: 001 | loss: 3.35118 - acc: 0.0587 -- iter: 0512/1224\n",
            "Training Step: 9  | total loss: \u001b[1m\u001b[32m3.38994\u001b[0m\u001b[0m | time: 154.996s\n",
            "| Momentum | epoch: 001 | loss: 3.38994 - acc: 0.0772 -- iter: 0576/1224\n",
            "Training Step: 10  | total loss: \u001b[1m\u001b[32m3.44619\u001b[0m\u001b[0m | time: 171.841s\n",
            "| Momentum | epoch: 001 | loss: 3.44619 - acc: 0.0621 -- iter: 0640/1224\n",
            "Training Step: 11  | total loss: \u001b[1m\u001b[32m3.26931\u001b[0m\u001b[0m | time: 188.953s\n",
            "| Momentum | epoch: 001 | loss: 3.26931 - acc: 0.0771 -- iter: 0704/1224\n",
            "Training Step: 12  | total loss: \u001b[1m\u001b[32m3.26114\u001b[0m\u001b[0m | time: 206.018s\n",
            "| Momentum | epoch: 001 | loss: 3.26114 - acc: 0.0775 -- iter: 0768/1224\n",
            "Training Step: 13  | total loss: \u001b[1m\u001b[32m3.30682\u001b[0m\u001b[0m | time: 222.461s\n",
            "| Momentum | epoch: 001 | loss: 3.30682 - acc: 0.0779 -- iter: 0832/1224\n",
            "Training Step: 14  | total loss: \u001b[1m\u001b[32m3.30682\u001b[0m\u001b[0m | time: 239.231s\n",
            "| Momentum | epoch: 001 | loss: 3.30682 - acc: 0.0779 -- iter: 0896/1224\n",
            "Training Step: 15  | total loss: \u001b[1m\u001b[32m3.31133\u001b[0m\u001b[0m | time: 255.924s\n",
            "| Momentum | epoch: 001 | loss: 3.31133 - acc: 0.0780 -- iter: 0960/1224\n",
            "Training Step: 16  | total loss: \u001b[1m\u001b[32m3.29374\u001b[0m\u001b[0m | time: 272.576s\n",
            "| Momentum | epoch: 001 | loss: 3.29374 - acc: 0.0898 -- iter: 1024/1224\n",
            "Training Step: 17  | total loss: \u001b[1m\u001b[32m3.36255\u001b[0m\u001b[0m | time: 288.971s\n",
            "| Momentum | epoch: 001 | loss: 3.36255 - acc: 0.0743 -- iter: 1088/1224\n",
            "Training Step: 18  | total loss: \u001b[1m\u001b[32m3.30978\u001b[0m\u001b[0m | time: 305.827s\n",
            "| Momentum | epoch: 001 | loss: 3.30978 - acc: 0.0702 -- iter: 1152/1224\n",
            "Training Step: 19  | total loss: \u001b[1m\u001b[32m3.33463\u001b[0m\u001b[0m | time: 322.301s\n",
            "| Momentum | epoch: 001 | loss: 3.33463 - acc: 0.0833 -- iter: 1216/1224\n",
            "Training Step: 20  | total loss: \u001b[1m\u001b[32m3.30244\u001b[0m\u001b[0m | time: 331.749s\n",
            "| Momentum | epoch: 001 | loss: 3.30244 - acc: 0.0866 -- iter: 1224/1224\n",
            "save model...\n",
            "---------------------------------\n",
            "Run id: alexnet_oxflowers17\n",
            "Log directory: output/\n",
            "---------------------------------\n",
            "Training samples: 1224\n",
            "Validation samples: 136\n",
            "--\n",
            "Training Step: 21  | total loss: \u001b[1m\u001b[32m3.13195\u001b[0m\u001b[0m | time: 16.928s\n",
            "| Momentum | epoch: 002 | loss: 3.13195 - acc: 0.0985 -- iter: 0064/1224\n",
            "Training Step: 22  | total loss: \u001b[1m\u001b[32m3.11977\u001b[0m\u001b[0m | time: 33.844s\n",
            "| Momentum | epoch: 002 | loss: 3.11977 - acc: 0.0971 -- iter: 0128/1224\n",
            "Training Step: 23  | total loss: \u001b[1m\u001b[32m3.15782\u001b[0m\u001b[0m | time: 50.756s\n",
            "| Momentum | epoch: 002 | loss: 3.15782 - acc: 0.1007 -- iter: 0192/1224\n",
            "Training Step: 24  | total loss: \u001b[1m\u001b[32m3.15981\u001b[0m\u001b[0m | time: 67.534s\n",
            "| Momentum | epoch: 002 | loss: 3.15981 - acc: 0.0855 -- iter: 0256/1224\n",
            "Training Step: 25  | total loss: \u001b[1m\u001b[32m3.22287\u001b[0m\u001b[0m | time: 84.148s\n",
            "| Momentum | epoch: 002 | loss: 3.22287 - acc: 0.0793 -- iter: 0320/1224\n",
            "Training Step: 26  | total loss: \u001b[1m\u001b[32m3.27690\u001b[0m\u001b[0m | time: 100.806s\n",
            "| Momentum | epoch: 002 | loss: 3.27690 - acc: 0.0655 -- iter: 0384/1224\n",
            "Training Step: 27  | total loss: \u001b[1m\u001b[32m3.26489\u001b[0m\u001b[0m | time: 117.578s\n",
            "| Momentum | epoch: 002 | loss: 3.26489 - acc: 0.0655 -- iter: 0448/1224\n",
            "Training Step: 28  | total loss: \u001b[1m\u001b[32m3.23664\u001b[0m\u001b[0m | time: 134.041s\n",
            "| Momentum | epoch: 002 | loss: 3.23664 - acc: 0.0651 -- iter: 0512/1224\n",
            "Training Step: 29  | total loss: \u001b[1m\u001b[32m3.26727\u001b[0m\u001b[0m | time: 150.418s\n",
            "| Momentum | epoch: 002 | loss: 3.26727 - acc: 0.0681 -- iter: 0576/1224\n",
            "Training Step: 30  | total loss: \u001b[1m\u001b[32m3.32018\u001b[0m\u001b[0m | time: 166.798s\n",
            "| Momentum | epoch: 002 | loss: 3.32018 - acc: 0.0560 -- iter: 0640/1224\n",
            "Training Step: 31  | total loss: \u001b[1m\u001b[32m3.32018\u001b[0m\u001b[0m | time: 183.444s\n",
            "| Momentum | epoch: 002 | loss: 3.32018 - acc: 0.0560 -- iter: 0704/1224\n",
            "Training Step: 32  | total loss: \u001b[1m\u001b[32m3.26606\u001b[0m\u001b[0m | time: 200.103s\n",
            "| Momentum | epoch: 002 | loss: 3.26606 - acc: 0.0680 -- iter: 0768/1224\n",
            "Training Step: 33  | total loss: \u001b[1m\u001b[32m3.25833\u001b[0m\u001b[0m | time: 216.590s\n",
            "| Momentum | epoch: 002 | loss: 3.25833 - acc: 0.0702 -- iter: 0832/1224\n",
            "Training Step: 34  | total loss: \u001b[1m\u001b[32m3.29735\u001b[0m\u001b[0m | time: 233.071s\n",
            "| Momentum | epoch: 002 | loss: 3.29735 - acc: 0.0719 -- iter: 0896/1224\n",
            "Training Step: 35  | total loss: \u001b[1m\u001b[32m3.27786\u001b[0m\u001b[0m | time: 249.697s\n",
            "| Momentum | epoch: 002 | loss: 3.27786 - acc: 0.0732 -- iter: 0960/1224\n",
            "Training Step: 36  | total loss: \u001b[1m\u001b[32m3.22408\u001b[0m\u001b[0m | time: 266.512s\n",
            "| Momentum | epoch: 002 | loss: 3.22408 - acc: 0.0710 -- iter: 1024/1224\n",
            "Training Step: 37  | total loss: \u001b[1m\u001b[32m3.21068\u001b[0m\u001b[0m | time: 283.907s\n",
            "| Momentum | epoch: 002 | loss: 3.21068 - acc: 0.0725 -- iter: 1088/1224\n",
            "Training Step: 38  | total loss: \u001b[1m\u001b[32m3.18720\u001b[0m\u001b[0m | time: 300.534s\n",
            "| Momentum | epoch: 002 | loss: 3.18720 - acc: 0.0739 -- iter: 1152/1224\n",
            "Training Step: 39  | total loss: \u001b[1m\u001b[32m3.22044\u001b[0m\u001b[0m | time: 317.087s\n",
            "| Momentum | epoch: 002 | loss: 3.22044 - acc: 0.0739 -- iter: 1216/1224\n",
            "Training Step: 40  | total loss: \u001b[1m\u001b[32m3.21814\u001b[0m\u001b[0m | time: 326.459s\n",
            "| Momentum | epoch: 002 | loss: 3.21814 - acc: 0.0718 -- iter: 1224/1224\n",
            "save model...\n",
            "---------------------------------\n",
            "Run id: alexnet_oxflowers17\n",
            "Log directory: output/\n",
            "---------------------------------\n",
            "Training samples: 1224\n",
            "Validation samples: 136\n",
            "--\n",
            "Training Step: 41  | total loss: \u001b[1m\u001b[32m3.13452\u001b[0m\u001b[0m | time: 16.943s\n",
            "| Momentum | epoch: 003 | loss: 3.13452 - acc: 0.1275 -- iter: 0064/1224\n",
            "Training Step: 42  | total loss: \u001b[1m\u001b[32m3.18631\u001b[0m\u001b[0m | time: 33.641s\n",
            "| Momentum | epoch: 003 | loss: 3.18631 - acc: 0.1130 -- iter: 0128/1224\n",
            "Training Step: 43  | total loss: \u001b[1m\u001b[32m3.18319\u001b[0m\u001b[0m | time: 50.179s\n",
            "| Momentum | epoch: 003 | loss: 3.18319 - acc: 0.1123 -- iter: 0192/1224\n",
            "Training Step: 44  | total loss: \u001b[1m\u001b[32m3.17753\u001b[0m\u001b[0m | time: 66.609s\n",
            "| Momentum | epoch: 003 | loss: 3.17753 - acc: 0.1118 -- iter: 0256/1224\n",
            "Training Step: 45  | total loss: \u001b[1m\u001b[32m3.17403\u001b[0m\u001b[0m | time: 83.049s\n",
            "| Momentum | epoch: 003 | loss: 3.17403 - acc: 0.1008 -- iter: 0320/1224\n",
            "Training Step: 46  | total loss: \u001b[1m\u001b[32m3.14235\u001b[0m\u001b[0m | time: 99.349s\n",
            "| Momentum | epoch: 003 | loss: 3.14235 - acc: 0.0996 -- iter: 0384/1224\n",
            "Training Step: 47  | total loss: \u001b[1m\u001b[32m3.15856\u001b[0m\u001b[0m | time: 115.635s\n",
            "| Momentum | epoch: 003 | loss: 3.15856 - acc: 0.0961 -- iter: 0448/1224\n",
            "Training Step: 48  | total loss: \u001b[1m\u001b[32m3.15188\u001b[0m\u001b[0m | time: 131.936s\n",
            "| Momentum | epoch: 003 | loss: 3.15188 - acc: 0.0932 -- iter: 0512/1224\n",
            "Training Step: 49  | total loss: \u001b[1m\u001b[32m3.12748\u001b[0m\u001b[0m | time: 148.330s\n",
            "| Momentum | epoch: 003 | loss: 3.12748 - acc: 0.0859 -- iter: 0576/1224\n",
            "Training Step: 50  | total loss: \u001b[1m\u001b[32m3.14829\u001b[0m\u001b[0m | time: 164.928s\n",
            "| Momentum | epoch: 003 | loss: 3.14829 - acc: 0.0871 -- iter: 0640/1224\n",
            "Training Step: 51  | total loss: \u001b[1m\u001b[32m3.14765\u001b[0m\u001b[0m | time: 181.317s\n",
            "| Momentum | epoch: 003 | loss: 3.14765 - acc: 0.0857 -- iter: 0704/1224\n",
            "Training Step: 52  | total loss: \u001b[1m\u001b[32m3.14691\u001b[0m\u001b[0m | time: 197.972s\n",
            "| Momentum | epoch: 003 | loss: 3.14691 - acc: 0.0776 -- iter: 0768/1224\n",
            "Training Step: 53  | total loss: \u001b[1m\u001b[32m3.19246\u001b[0m\u001b[0m | time: 214.404s\n",
            "| Momentum | epoch: 003 | loss: 3.19246 - acc: 0.0800 -- iter: 0832/1224\n",
            "Training Step: 54  | total loss: \u001b[1m\u001b[32m3.19246\u001b[0m\u001b[0m | time: 230.559s\n",
            "| Momentum | epoch: 003 | loss: 3.19246 - acc: 0.0752 -- iter: 0896/1224\n",
            "Training Step: 55  | total loss: \u001b[1m\u001b[32m3.23126\u001b[0m\u001b[0m | time: 247.219s\n",
            "| Momentum | epoch: 003 | loss: 3.23126 - acc: 0.0689 -- iter: 0960/1224\n",
            "Training Step: 56  | total loss: \u001b[1m\u001b[32m3.21088\u001b[0m\u001b[0m | time: 263.640s\n",
            "| Momentum | epoch: 003 | loss: 3.21088 - acc: 0.0746 -- iter: 1024/1224\n",
            "Training Step: 57  | total loss: \u001b[1m\u001b[32m3.20573\u001b[0m\u001b[0m | time: 280.124s\n",
            "| Momentum | epoch: 003 | loss: 3.20573 - acc: 0.0772 -- iter: 1088/1224\n",
            "Training Step: 58  | total loss: \u001b[1m\u001b[32m3.19750\u001b[0m\u001b[0m | time: 296.471s\n",
            "| Momentum | epoch: 003 | loss: 3.19750 - acc: 0.0731 -- iter: 1152/1224\n",
            "Training Step: 59  | total loss: \u001b[1m\u001b[32m3.19669\u001b[0m\u001b[0m | time: 313.110s\n",
            "| Momentum | epoch: 003 | loss: 3.19669 - acc: 0.0759 -- iter: 1216/1224\n",
            "Training Step: 60  | total loss: \u001b[1m\u001b[32m3.21829\u001b[0m\u001b[0m | time: 322.252s\n",
            "| Momentum | epoch: 003 | loss: 3.21829 - acc: 0.0803 -- iter: 1224/1224\n",
            "save model...\n",
            "---------------------------------\n",
            "Run id: alexnet_oxflowers17\n",
            "Log directory: output/\n",
            "---------------------------------\n",
            "Training samples: 1224\n",
            "Validation samples: 136\n",
            "--\n",
            "Training Step: 61  | total loss: \u001b[1m\u001b[32m3.21829\u001b[0m\u001b[0m | time: 16.953s\n",
            "| Momentum | epoch: 004 | loss: 3.21829 - acc: 0.0861 -- iter: 0064/1224\n",
            "Training Step: 62  | total loss: \u001b[1m\u001b[32m3.24176\u001b[0m\u001b[0m | time: 33.506s\n",
            "| Momentum | epoch: 004 | loss: 3.24176 - acc: 0.0771 -- iter: 0128/1224\n",
            "Training Step: 63  | total loss: \u001b[1m\u001b[32m3.23024\u001b[0m\u001b[0m | time: 49.729s\n",
            "| Momentum | epoch: 004 | loss: 3.23024 - acc: 0.0772 -- iter: 0192/1224\n",
            "Training Step: 64  | total loss: \u001b[1m\u001b[32m3.19187\u001b[0m\u001b[0m | time: 66.310s\n",
            "| Momentum | epoch: 004 | loss: 3.19187 - acc: 0.0871 -- iter: 0256/1224\n",
            "Training Step: 65  | total loss: \u001b[1m\u001b[32m3.18245\u001b[0m\u001b[0m | time: 82.706s\n",
            "| Momentum | epoch: 004 | loss: 3.18245 - acc: 0.0898 -- iter: 0320/1224\n",
            "Training Step: 66  | total loss: \u001b[1m\u001b[32m3.19867\u001b[0m\u001b[0m | time: 98.903s\n",
            "| Momentum | epoch: 004 | loss: 3.19867 - acc: 0.0865 -- iter: 0384/1224\n",
            "Training Step: 67  | total loss: \u001b[1m\u001b[32m3.19248\u001b[0m\u001b[0m | time: 115.486s\n",
            "| Momentum | epoch: 004 | loss: 3.19248 - acc: 0.0836 -- iter: 0448/1224\n",
            "Training Step: 68  | total loss: \u001b[1m\u001b[32m3.19990\u001b[0m\u001b[0m | time: 131.809s\n",
            "| Momentum | epoch: 004 | loss: 3.19990 - acc: 0.0830 -- iter: 0512/1224\n",
            "Training Step: 69  | total loss: \u001b[1m\u001b[32m3.20617\u001b[0m\u001b[0m | time: 148.978s\n",
            "| Momentum | epoch: 004 | loss: 3.20617 - acc: 0.0879 -- iter: 0576/1224\n",
            "Training Step: 70  | total loss: \u001b[1m\u001b[32m3.17792\u001b[0m\u001b[0m | time: 165.442s\n",
            "| Momentum | epoch: 004 | loss: 3.17792 - acc: 0.0958 -- iter: 0640/1224\n",
            "Training Step: 71  | total loss: \u001b[1m\u001b[32m3.16557\u001b[0m\u001b[0m | time: 181.965s\n",
            "| Momentum | epoch: 004 | loss: 3.16557 - acc: 0.0973 -- iter: 0704/1224\n",
            "Training Step: 72  | total loss: \u001b[1m\u001b[32m3.17253\u001b[0m\u001b[0m | time: 198.416s\n",
            "| Momentum | epoch: 004 | loss: 3.17253 - acc: 0.0899 -- iter: 0768/1224\n",
            "Training Step: 73  | total loss: \u001b[1m\u001b[32m3.17003\u001b[0m\u001b[0m | time: 214.834s\n",
            "| Momentum | epoch: 004 | loss: 3.17003 - acc: 0.0886 -- iter: 0832/1224\n",
            "Training Step: 74  | total loss: \u001b[1m\u001b[32m3.17095\u001b[0m\u001b[0m | time: 231.582s\n",
            "| Momentum | epoch: 004 | loss: 3.17095 - acc: 0.0892 -- iter: 0896/1224\n",
            "Training Step: 75  | total loss: \u001b[1m\u001b[32m3.14734\u001b[0m\u001b[0m | time: 248.978s\n",
            "| Momentum | epoch: 004 | loss: 3.14734 - acc: 0.0896 -- iter: 0960/1224\n",
            "Training Step: 76  | total loss: \u001b[1m\u001b[32m3.12872\u001b[0m\u001b[0m | time: 265.060s\n",
            "| Momentum | epoch: 004 | loss: 3.12872 - acc: 0.0951 -- iter: 1024/1224\n",
            "Training Step: 77  | total loss: \u001b[1m\u001b[32m3.13582\u001b[0m\u001b[0m | time: 281.354s\n",
            "| Momentum | epoch: 004 | loss: 3.13582 - acc: 0.0883 -- iter: 1088/1224\n",
            "Training Step: 78  | total loss: \u001b[1m\u001b[32m3.12088\u001b[0m\u001b[0m | time: 297.695s\n",
            "| Momentum | epoch: 004 | loss: 3.12088 - acc: 0.0922 -- iter: 1152/1224\n",
            "Training Step: 79  | total loss: \u001b[1m\u001b[32m3.11692\u001b[0m\u001b[0m | time: 314.022s\n",
            "| Momentum | epoch: 004 | loss: 3.11692 - acc: 0.0923 -- iter: 1216/1224\n",
            "Training Step: 80  | total loss: \u001b[1m\u001b[32m3.11917\u001b[0m\u001b[0m | time: 323.195s\n",
            "| Momentum | epoch: 004 | loss: 3.11917 - acc: 0.0877 -- iter: 1224/1224\n",
            "save model...\n",
            "---------------------------------\n",
            "Run id: alexnet_oxflowers17\n",
            "Log directory: output/\n",
            "---------------------------------\n",
            "Training samples: 1224\n",
            "Validation samples: 136\n",
            "--\n",
            "Training Step: 81  | total loss: \u001b[1m\u001b[32m3.11471\u001b[0m\u001b[0m | time: 16.669s\n",
            "| Momentum | epoch: 005 | loss: 3.11471 - acc: 0.1041 -- iter: 0064/1224\n",
            "Training Step: 82  | total loss: \u001b[1m\u001b[32m3.12615\u001b[0m\u001b[0m | time: 33.301s\n",
            "| Momentum | epoch: 005 | loss: 3.12615 - acc: 0.0984 -- iter: 0128/1224\n",
            "Training Step: 83  | total loss: \u001b[1m\u001b[32m3.17383\u001b[0m\u001b[0m | time: 49.833s\n",
            "| Momentum | epoch: 005 | loss: 3.17383 - acc: 0.0917 -- iter: 0192/1224\n",
            "Training Step: 84  | total loss: \u001b[1m\u001b[32m3.17902\u001b[0m\u001b[0m | time: 66.271s\n",
            "| Momentum | epoch: 005 | loss: 3.17902 - acc: 0.0950 -- iter: 0256/1224\n",
            "Training Step: 85  | total loss: \u001b[1m\u001b[32m3.19573\u001b[0m\u001b[0m | time: 82.748s\n",
            "| Momentum | epoch: 005 | loss: 3.19573 - acc: 0.0933 -- iter: 0320/1224\n",
            "Training Step: 86  | total loss: \u001b[1m\u001b[32m3.19062\u001b[0m\u001b[0m | time: 99.314s\n",
            "| Momentum | epoch: 005 | loss: 3.19062 - acc: 0.0934 -- iter: 0384/1224\n",
            "Training Step: 87  | total loss: \u001b[1m\u001b[32m3.20011\u001b[0m\u001b[0m | time: 115.774s\n",
            "| Momentum | epoch: 005 | loss: 3.20011 - acc: 0.0871 -- iter: 0448/1224\n",
            "Training Step: 88  | total loss: \u001b[1m\u001b[32m3.20278\u001b[0m\u001b[0m | time: 132.319s\n",
            "| Momentum | epoch: 005 | loss: 3.20278 - acc: 0.0847 -- iter: 0512/1224\n",
            "Training Step: 89  | total loss: \u001b[1m\u001b[32m3.19463\u001b[0m\u001b[0m | time: 148.926s\n",
            "| Momentum | epoch: 005 | loss: 3.19463 - acc: 0.0856 -- iter: 0576/1224\n",
            "Training Step: 90  | total loss: \u001b[1m\u001b[32m3.18058\u001b[0m\u001b[0m | time: 165.511s\n",
            "| Momentum | epoch: 005 | loss: 3.18058 - acc: 0.0848 -- iter: 0640/1224\n",
            "Training Step: 91  | total loss: \u001b[1m\u001b[32m3.15377\u001b[0m\u001b[0m | time: 181.913s\n",
            "| Momentum | epoch: 005 | loss: 3.15377 - acc: 0.0935 -- iter: 0704/1224\n",
            "Training Step: 92  | total loss: \u001b[1m\u001b[32m3.14735\u001b[0m\u001b[0m | time: 198.250s\n",
            "| Momentum | epoch: 005 | loss: 3.14735 - acc: 0.0920 -- iter: 0768/1224\n",
            "Training Step: 93  | total loss: \u001b[1m\u001b[32m3.12555\u001b[0m\u001b[0m | time: 214.628s\n",
            "| Momentum | epoch: 005 | loss: 3.12555 - acc: 0.0922 -- iter: 0832/1224\n",
            "Training Step: 94  | total loss: \u001b[1m\u001b[32m3.14662\u001b[0m\u001b[0m | time: 231.098s\n",
            "| Momentum | epoch: 005 | loss: 3.14662 - acc: 0.0892 -- iter: 0896/1224\n",
            "Training Step: 95  | total loss: \u001b[1m\u001b[32m3.13622\u001b[0m\u001b[0m | time: 247.322s\n",
            "| Momentum | epoch: 005 | loss: 3.13622 - acc: 0.0946 -- iter: 0960/1224\n",
            "Training Step: 96  | total loss: \u001b[1m\u001b[32m3.14360\u001b[0m\u001b[0m | time: 263.827s\n",
            "| Momentum | epoch: 005 | loss: 3.14360 - acc: 0.0946 -- iter: 1024/1224\n",
            "Training Step: 97  | total loss: \u001b[1m\u001b[32m3.13965\u001b[0m\u001b[0m | time: 279.776s\n",
            "| Momentum | epoch: 005 | loss: 3.13965 - acc: 0.0883 -- iter: 1088/1224\n",
            "Training Step: 98  | total loss: \u001b[1m\u001b[32m3.16339\u001b[0m\u001b[0m | time: 296.336s\n",
            "| Momentum | epoch: 005 | loss: 3.16339 - acc: 0.0883 -- iter: 1152/1224\n",
            "Training Step: 99  | total loss: \u001b[1m\u001b[32m3.13889\u001b[0m\u001b[0m | time: 312.632s\n",
            "| Momentum | epoch: 005 | loss: 3.13889 - acc: 0.0951 -- iter: 1216/1224\n",
            "Training Step: 100  | total loss: \u001b[1m\u001b[32m3.13750\u001b[0m\u001b[0m | time: 321.769s\n",
            "| Momentum | epoch: 005 | loss: 3.13750 - acc: 0.0934 -- iter: 1224/1224\n",
            "save model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x05Sezg8M94x"
      },
      "source": [
        "Google drive mount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkFAKHcMbYsp"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZeVhi72NeYB"
      },
      "source": [
        "Model create &\r\n",
        "Load weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feVk9ZC0NESY"
      },
      "source": [
        "# Use a already trained alexnet with the last layer redesigned\r\n",
        "def create_alexnet():\r\n",
        "    # Building 'AlexNet'\r\n",
        "    network = input_data(shape=[None, config.IMAGE_SIZE, config.IMAGE_SIZE, 3])\r\n",
        "    network = conv_2d(network, 96, 11, strides=4, activation='relu')\r\n",
        "    network = max_pool_2d(network, 3, strides=2)\r\n",
        "    network = local_response_normalization(network)\r\n",
        "    network = conv_2d(network, 256, 5, activation='relu')\r\n",
        "    network = max_pool_2d(network, 3, strides=2)\r\n",
        "    network = local_response_normalization(network)\r\n",
        "    network = conv_2d(network, 384, 3, activation='relu')\r\n",
        "    network = conv_2d(network, 384, 3, activation='relu')\r\n",
        "    network = conv_2d(network, 256, 3, activation='relu')\r\n",
        "    network = max_pool_2d(network, 3, strides=2)\r\n",
        "    network = local_response_normalization(network)\r\n",
        "    network = fully_connected(network, 4096, activation='tanh')\r\n",
        "    network = dropout(network, 0.5)\r\n",
        "    network = fully_connected(network, 4096, activation='tanh')\r\n",
        "    network = regression(network, optimizer='momentum',\r\n",
        "                         loss='categorical_crossentropy',\r\n",
        "                         learning_rate=0.001)\r\n",
        "    return network\r\n",
        "    \r\n",
        "model = tflearn.DNN(net)\r\n",
        "model.load('/content/drive/MyDrive/RCNN/pre_train_model/model_save.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WejBQsxORTi"
      },
      "source": [
        "Inference latent vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvlQ3HoEP36c"
      },
      "source": [
        "from train_alexnet import *\r\n",
        "\r\n",
        "train_list = './train_list.txt'\r\n",
        "train_class = 17\r\n",
        "X, Y = load_data(train_list, train_class)\r\n",
        "\r\n",
        "N = len(X)\r\n",
        "offset = 100\r\n",
        "latent_vector_len = 4096\r\n",
        "train_latent = np.zeros((N,latent_vector_len))\r\n",
        "\r\n",
        "\r\n",
        "for i in range(0,N,offset):\r\n",
        "  train_latent[i:i + offset] = model.predict(X[i:i + offset])\r\n",
        "  print(f'{i}/{N}')\r\n",
        "\r\n",
        "train_latent.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSBE7YXxOwNk"
      },
      "source": [
        "Visualize latent space by PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVzGPsA4RGdu"
      },
      "source": [
        "from sklearn.decomposition import PCA\r\n",
        "\r\n",
        "pca = PCA(n_components=2)\r\n",
        "class_batch = 80\r\n",
        "nn = 7\r\n",
        "\r\n",
        "fig = plt.figure(figsize=(20,20))\r\n",
        "\r\n",
        "for i in range(nn):\r\n",
        "  for j in range(i,nn):\r\n",
        "    ax = fig.add_subplot(nn,nn,i*nn+j+1)\r\n",
        "    if(i != j):\r\n",
        "      i_range = np.arange(i*class_batch,(i+1)*class_batch)\r\n",
        "      j_range = np.arange(j*class_batch,(j+1)*class_batch)\r\n",
        "      pca.fit(train_latent[np.append(i_range,j_range)])\r\n",
        "      xy = pca.transform(train_latent[np.append(i_range,j_range)])\r\n",
        "      \r\n",
        "      ax.scatter(xy[:class_batch,0],xy[:class_batch,1],label= f'class:{i}',s=15)\r\n",
        "      ax.scatter(xy[class_batch:,0],xy[class_batch:,1],label= f'class:{j}',s=15)\r\n",
        "      ax.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsBrSPyOPOXQ"
      },
      "source": [
        "# Model fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljo-5_wvPWBb"
      },
      "source": [
        "Load fine-tuning dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZHUMPgI3Jlw"
      },
      "source": [
        "import numpy as np\r\n",
        "import os\r\n",
        "import tools\r\n",
        "\r\n",
        "data_set = '/content/drive/MyDrive/RCNN/data_set'\r\n",
        "\r\n",
        "def load_from_npy(data_set):\r\n",
        "    images, labels = [], []\r\n",
        "    data_list = os.listdir(data_set)\r\n",
        "    data_list.sort()\r\n",
        "    # random.shuffle(data_list)\r\n",
        "    for ind, d in enumerate(data_list):\r\n",
        "        i, l = np.load(os.path.join(data_set, d),allow_pickle=True)\r\n",
        "        images.extend(i)\r\n",
        "        labels.extend(l)\r\n",
        "        tools.view_bar(\"load data of %s\" % d, ind + 1, len(data_list))\r\n",
        "    print(' ')\r\n",
        "    return images, labels\r\n",
        "\r\n",
        "X, Y = load_from_npy(data_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb_0G0xFPbU_"
      },
      "source": [
        "Visualize fine-tuning dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SzTNqQv3WHC"
      },
      "source": [
        "import matplotlib.patches as mpatches\r\n",
        "from  preprocessing_RCNN import *\r\n",
        "from RCNN_output import *\r\n",
        "\r\n",
        "img_path = './2flowers/jpg/0/image_0561.jpg' \r\n",
        "imgs, verts = image_proposal(img_path)\r\n",
        "gt = [90,126,350,434]\r\n",
        "\r\n",
        "fig = plt.figure(figsize=(10,5))\r\n",
        "\r\n",
        "img = skimage.io.imread(img_path)\r\n",
        "ax = fig.add_subplot(1,2,1)\r\n",
        "ax.set_title('region proposal')\r\n",
        "ax.imshow(img)\r\n",
        "for x, y, w, h in verts:\r\n",
        "    rect = mpatches.Rectangle(\r\n",
        "        (x, y), w, h, fill=False, edgecolor='red', linewidth=1)\r\n",
        "    ax.add_patch(rect)\r\n",
        "\r\n",
        "ax = fig.add_subplot(1,2,2)\r\n",
        "ax.set_title('ground truth')\r\n",
        "ax.imshow(img)\r\n",
        "[x, y, w, h] = gt\r\n",
        "rect = mpatches.Rectangle(\r\n",
        "    (x, y), w, h, fill=False, edgecolor='green', linewidth=1)\r\n",
        "ax.add_patch(rect)\r\n",
        "plt.show()\r\n",
        "\r\n",
        "fig = plt.figure(figsize=(20,10))\r\n",
        "for i,(x,r) in enumerate(zip(imgs[2:10], verts[2:10])):\r\n",
        "  ax = fig.add_subplot(1,8,i+1)\r\n",
        "  ax.imshow(img)\r\n",
        "\r\n",
        "  proposal_img, proposal_vertice = clip_pic(img, r)\r\n",
        "  iou = IOU(gt, proposal_vertice)\r\n",
        "  ax.set_title(f'IOU:{iou:.3f}')\r\n",
        "\r\n",
        "  [x, y, w, h] = gt\r\n",
        "  rect = mpatches.Rectangle(\r\n",
        "        (x, y), w, h, fill=False, edgecolor='green', linewidth=1)\r\n",
        "  ax.add_patch(rect)\r\n",
        "\r\n",
        "  x, y, w, h = r\r\n",
        "  rect = mpatches.Rectangle(\r\n",
        "        (x, y), w, h, fill=False, edgecolor='red', linewidth=1)\r\n",
        "  ax.add_patch(rect)\r\n",
        "\r\n",
        "plt.show()\r\n",
        "\r\n",
        "fig = plt.figure(figsize=(20,10))\r\n",
        "for i,(x,y) in enumerate(zip(X[2:10],Y[2:10])):\r\n",
        "  ax = fig.add_subplot(1,8,i+1)\r\n",
        "  ax.imshow(np.array(x,dtype=np.int))\r\n",
        "  ax.set_title(str(y))\r\n",
        "plt.show()\r\n",
        "\r\n",
        "\r\n",
        "img_path = './2flowers/jpg/1/image_1282.jpg' \r\n",
        "imgs, verts = image_proposal(img_path)\r\n",
        "gt = [90,35,330,425]\r\n",
        "\r\n",
        "fig = plt.figure(figsize=(10,5))\r\n",
        "\r\n",
        "img = skimage.io.imread(img_path)\r\n",
        "ax = fig.add_subplot(1,2,1)\r\n",
        "ax.set_title('region proposal')\r\n",
        "ax.imshow(img)\r\n",
        "for x, y, w, h in verts:\r\n",
        "    rect = mpatches.Rectangle(\r\n",
        "        (x, y), w, h, fill=False, edgecolor='red', linewidth=1)\r\n",
        "    ax.add_patch(rect)\r\n",
        "\r\n",
        "ax = fig.add_subplot(1,2,2)\r\n",
        "ax.set_title('ground truth')\r\n",
        "ax.imshow(img)\r\n",
        "[x, y, w, h] = gt\r\n",
        "rect = mpatches.Rectangle(\r\n",
        "    (x, y), w, h, fill=False, edgecolor='green', linewidth=1)\r\n",
        "ax.add_patch(rect)\r\n",
        "plt.show()\r\n",
        "\r\n",
        "fig = plt.figure(figsize=(20,10))\r\n",
        "for i,(x,r) in enumerate(zip(imgs[3:11], verts[3:11])):\r\n",
        "  ax = fig.add_subplot(1,8,i+1)\r\n",
        "  ax.imshow(img)\r\n",
        "\r\n",
        "  proposal_img, proposal_vertice = clip_pic(img, r)\r\n",
        "  iou = IOU(gt, proposal_vertice)\r\n",
        "  ax.set_title(f'IOU:{iou:.3f}')\r\n",
        "\r\n",
        "  [x, y, w, h] = gt\r\n",
        "  rect = mpatches.Rectangle(\r\n",
        "        (x, y), w, h, fill=False, edgecolor='green', linewidth=1)\r\n",
        "  ax.add_patch(rect)\r\n",
        "\r\n",
        "  x, y, w, h = r\r\n",
        "  rect = mpatches.Rectangle(\r\n",
        "        (x, y), w, h, fill=False, edgecolor='red', linewidth=1)\r\n",
        "  ax.add_patch(rect)\r\n",
        "\r\n",
        "plt.show()\r\n",
        "\r\n",
        "fig = plt.figure(figsize=(20,10))\r\n",
        "for i,(x,y) in enumerate(zip(X[47:55],Y[47:55])):\r\n",
        "  ax = fig.add_subplot(1,8,i+1)\r\n",
        "  ax.imshow(np.array(x,dtype=np.int))\r\n",
        "  ax.set_title(str(y))\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wjyui7inPrIU"
      },
      "source": [
        "Model fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-w3YCYCV-sj"
      },
      "source": [
        "!python fine_tune_RCNN.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT8iFc8oKT9A",
        "outputId": "d7e53326-c172-4c0c-e194-b74e7a5dc909"
      },
      "source": [
        "!python fine_tune_RCNN.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-30 18:13:05.822781: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "Loading Data\n",
            "load data of image_1290_data.npy:[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100%\t60/60 \n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/initializations.py:110: calling UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:538: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/initializations.py:165: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "2021-01-30 18:13:09.576154: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-01-30 18:13:09.577497: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-01-30 18:13:09.591747: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-01-30 18:13:09.591807: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (6e3265f6f850): /proc/driver/nvidia/version does not exist\n",
            "2021-01-30 18:13:09.592385: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-01-30 18:13:09.981121: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)\n",
            "2021-01-30 18:13:09.991926: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2249995000 Hz\n",
            "2021-01-30 18:13:10.015994: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 205520896 exceeds 10% of free system memory.\n",
            "2021-01-30 18:13:10.133614: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 205520896 exceeds 10% of free system memory.\n",
            "2021-01-30 18:13:10.209446: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 205520896 exceeds 10% of free system memory.\n",
            "2021-01-30 18:13:10.285112: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 205520896 exceeds 10% of free system memory.\n",
            "2021-01-30 18:13:10.387681: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 205520896 exceeds 10% of free system memory.\n",
            "2021-01-30 18:13:12.353913: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "Loading the alexnet\n",
            "2021-01-30 18:13:12.406611: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-01-30 18:13:21.890172: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "---------------------------------\n",
            "Run id: alexnet_rcnnflowers2\n",
            "Log directory: output_RCNN/\n",
            "tcmalloc: large alloc 2713116672 bytes == 0x1014a4000 @  0x7f0d251611e7 0x7f0d22ce141e 0x7f0d22d31c2b 0x7f0d22d34e33 0x7f0d22d3502b 0x7f0d22dd6701 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x5095c8 0x50a2fd 0x50beb4 0x507be4 0x50ad03 0x634e72 0x634f27 0x6386df\n",
            "---------------------------------\n",
            "Training samples: 4055\n",
            "Validation samples: 451\n",
            "--\n",
            "Training Step: 101  | total loss: \u001b[1m\u001b[32m3.11755\u001b[0m\u001b[0m | time: 19.464s\n",
            "| Momentum | epoch: 001 | loss: 3.11755 - acc: 0.0815 -- iter: 0064/4055\n",
            "Training Step: 102  | total loss: \u001b[1m\u001b[32m3.01650\u001b[0m\u001b[0m | time: 37.460s\n",
            "| Momentum | epoch: 001 | loss: 3.01650 - acc: 0.0858 -- iter: 0128/4055\n",
            "Training Step: 103  | total loss: \u001b[1m\u001b[32m2.90231\u001b[0m\u001b[0m | time: 55.740s\n",
            "| Momentum | epoch: 001 | loss: 2.90231 - acc: 0.0944 -- iter: 0192/4055\n",
            "Training Step: 104  | total loss: \u001b[1m\u001b[32m2.76093\u001b[0m\u001b[0m | time: 73.377s\n",
            "| Momentum | epoch: 001 | loss: 2.76093 - acc: 0.1147 -- iter: 0256/4055\n",
            "Training Step: 105  | total loss: \u001b[1m\u001b[32m2.57798\u001b[0m\u001b[0m | time: 91.365s\n",
            "| Momentum | epoch: 001 | loss: 2.57798 - acc: 0.1532 -- iter: 0320/4055\n",
            "Training Step: 106  | total loss: \u001b[1m\u001b[32m2.37923\u001b[0m\u001b[0m | time: 109.147s\n",
            "| Momentum | epoch: 001 | loss: 2.37923 - acc: 0.2160 -- iter: 0384/4055\n",
            "Training Step: 107  | total loss: \u001b[1m\u001b[32m2.17527\u001b[0m\u001b[0m | time: 126.870s\n",
            "| Momentum | epoch: 001 | loss: 2.17527 - acc: 0.2850 -- iter: 0448/4055\n",
            "Training Step: 108  | total loss: \u001b[1m\u001b[32m1.98127\u001b[0m\u001b[0m | time: 144.556s\n",
            "| Momentum | epoch: 001 | loss: 1.98127 - acc: 0.3518 -- iter: 0512/4055\n",
            "Training Step: 109  | total loss: \u001b[1m\u001b[32m1.82493\u001b[0m\u001b[0m | time: 162.339s\n",
            "| Momentum | epoch: 001 | loss: 1.82493 - acc: 0.4088 -- iter: 0576/4055\n",
            "Training Step: 110  | total loss: \u001b[1m\u001b[32m1.68604\u001b[0m\u001b[0m | time: 179.963s\n",
            "| Momentum | epoch: 001 | loss: 1.68604 - acc: 0.4601 -- iter: 0640/4055\n",
            "Training Step: 111  | total loss: \u001b[1m\u001b[32m1.56142\u001b[0m\u001b[0m | time: 197.629s\n",
            "| Momentum | epoch: 001 | loss: 1.56142 - acc: 0.5079 -- iter: 0704/4055\n",
            "Training Step: 112  | total loss: \u001b[1m\u001b[32m1.46411\u001b[0m\u001b[0m | time: 215.777s\n",
            "| Momentum | epoch: 001 | loss: 1.46411 - acc: 0.5493 -- iter: 0768/4055\n",
            "Training Step: 113  | total loss: \u001b[1m\u001b[32m1.35993\u001b[0m\u001b[0m | time: 233.719s\n",
            "| Momentum | epoch: 001 | loss: 1.35993 - acc: 0.5881 -- iter: 0832/4055\n",
            "Training Step: 114  | total loss: \u001b[1m\u001b[32m1.24194\u001b[0m\u001b[0m | time: 251.474s\n",
            "| Momentum | epoch: 001 | loss: 1.24194 - acc: 0.6262 -- iter: 0896/4055\n",
            "Training Step: 115  | total loss: \u001b[1m\u001b[32m1.15511\u001b[0m\u001b[0m | time: 269.224s\n",
            "| Momentum | epoch: 001 | loss: 1.15511 - acc: 0.6557 -- iter: 0960/4055\n",
            "Training Step: 116  | total loss: \u001b[1m\u001b[32m1.11686\u001b[0m\u001b[0m | time: 287.029s\n",
            "| Momentum | epoch: 001 | loss: 1.11686 - acc: 0.6792 -- iter: 1024/4055\n",
            "Training Step: 117  | total loss: \u001b[1m\u001b[32m1.05226\u001b[0m\u001b[0m | time: 304.606s\n",
            "| Momentum | epoch: 001 | loss: 1.05226 - acc: 0.7019 -- iter: 1088/4055\n",
            "Training Step: 118  | total loss: \u001b[1m\u001b[32m0.96694\u001b[0m\u001b[0m | time: 322.232s\n",
            "| Momentum | epoch: 001 | loss: 0.96694 - acc: 0.7286 -- iter: 1152/4055\n",
            "Training Step: 119  | total loss: \u001b[1m\u001b[32m0.89523\u001b[0m\u001b[0m | time: 339.844s\n",
            "| Momentum | epoch: 001 | loss: 0.89523 - acc: 0.7495 -- iter: 1216/4055\n",
            "Training Step: 120  | total loss: \u001b[1m\u001b[32m0.83231\u001b[0m\u001b[0m | time: 357.479s\n",
            "| Momentum | epoch: 001 | loss: 0.83231 - acc: 0.7683 -- iter: 1280/4055\n",
            "Training Step: 121  | total loss: \u001b[1m\u001b[32m0.78529\u001b[0m\u001b[0m | time: 375.449s\n",
            "| Momentum | epoch: 001 | loss: 0.78529 - acc: 0.7821 -- iter: 1344/4055\n",
            "Traceback (most recent call last):\n",
            "  File \"fine_tune_RCNN.py\", line 73, in <module>\n",
            "    fine_tune_Alexnet(net, X, Y, config.SAVE_MODEL_PATH, config.FINE_TUNE_MODEL_PATH)\n",
            "  File \"fine_tune_RCNN.py\", line 55, in fine_tune_Alexnet\n",
            "    snapshot_epoch=False, run_id='alexnet_rcnnflowers2')\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tflearn/models/dnn.py\", line 206, in fit\n",
            "    callbacks=callbacks)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tflearn/helpers/trainer.py\", line 344, in fit\n",
            "    show_metric)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tflearn/helpers/trainer.py\", line 828, in _train\n",
            "    feed_batch)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 968, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1191, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1369, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1375, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1360, in _run_fn\n",
            "    target_list, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1453, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFN_8uE7Pwk9"
      },
      "source": [
        "Load fine-tuning weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGI0K9qDTYJn"
      },
      "source": [
        "model.load('/content/drive/MyDrive/RCNN/fine_tune_model/fine_tune_model_save.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMd4QgFhSWfF"
      },
      "source": [
        "#Model test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCJ1E52qP4iK"
      },
      "source": [
        "Predict sample with SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Wm7raEipc2e"
      },
      "source": [
        "train_file_folder = '/content/drive/MyDrive/RCNN/svm_train'\r\n",
        "img_path = './17flowers/jpg/16/image_1281.jpg'  # or './17flowers/jpg/16/****.jpg'\r\n",
        "imgs, verts = image_proposal(img_path)\r\n",
        "tools.show_rect(img_path, verts)\r\n",
        "\r\n",
        "svms = []\r\n",
        "for file in os.listdir(train_file_folder):\r\n",
        "    if file.split('_')[-1] == 'svm.pkl':\r\n",
        "        svms.append(joblib.load(os.path.join(train_file_folder, file)))\r\n",
        "if len(svms) == 0:\r\n",
        "    svms = train_svms(train_file_folder, model)\r\n",
        "print(\"Done fitting svms\")\r\n",
        "features = model.predict(imgs)\r\n",
        "print(\"predict image:\")\r\n",
        "print(np.shape(features))\r\n",
        "results = []\r\n",
        "results_label = []\r\n",
        "count = 0\r\n",
        "conf_score = []\r\n",
        "\r\n",
        "for f in features:\r\n",
        "    for svm in svms:\r\n",
        "        pred = svm.predict([f.tolist()])\r\n",
        "        # not background\r\n",
        "        if pred[0] != 0:\r\n",
        "            results.append(verts[count])\r\n",
        "            results_label.append(pred[0])\r\n",
        "            conf_score.append(svm.decision_function([f.tolist()])[0])\r\n",
        "    count += 1\r\n",
        "print(\"result:\")\r\n",
        "print(results)\r\n",
        "print(\"result label:\")\r\n",
        "print(results_label)\r\n",
        "tools.show_rect(img_path, results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S094_iCYQ5TZ"
      },
      "source": [
        "Check confidence score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bE4GseQ0s4i5"
      },
      "source": [
        "conf_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHW-C6hO0xav"
      },
      "source": [
        "train_file_folder = '/content/drive/MyDrive/RCNN/svm_train'\r\n",
        "img_path = f'./17flowers/jpg/7/image_0563.jpg'\r\n",
        "imgs, verts = image_proposal(img_path)\r\n",
        "tools.show_rect(img_path, verts)\r\n",
        "\r\n",
        "svms = []\r\n",
        "for file in os.listdir(train_file_folder):\r\n",
        "    if file.split('_')[-1] == 'svm.pkl':\r\n",
        "        svms.append(joblib.load(os.path.join(train_file_folder, file)))\r\n",
        "if len(svms) == 0:\r\n",
        "    svms = train_svms(train_file_folder, model)\r\n",
        "print(\"Done fitting svms\")\r\n",
        "features = model.predict(imgs)\r\n",
        "print(\"predict image:\")\r\n",
        "print(np.shape(features))\r\n",
        "results = []\r\n",
        "results_label = []\r\n",
        "count = 0\r\n",
        "conf_score = []\r\n",
        "for f in features:\r\n",
        "    for svm in svms:\r\n",
        "        pred = svm.predict([f.tolist()])\r\n",
        "        # not background\r\n",
        "        if pred[0] != 0:\r\n",
        "            results.append(verts[count])\r\n",
        "            results_label.append(pred[0])\r\n",
        "            conf_score.append(svm.decision_function([f.tolist()])[0])\r\n",
        "    count += 1\r\n",
        "print(\"result:\")\r\n",
        "print(results)\r\n",
        "print(\"result label:\")\r\n",
        "print(results_label)\r\n",
        "tools.show_rect(img_path, results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV1kfzznu_HU"
      },
      "source": [
        "conf_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5lJeOOFS7G5"
      },
      "source": [
        "# Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb5hrvWxSAap"
      },
      "source": [
        "Get IOU score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIXpoevCQpTU"
      },
      "source": [
        "def get_IOU(img,region1, region2):\r\n",
        "  proposal_img, proposal_vertice1 = clip_pic(img, region1)\r\n",
        "  proposal_img, proposal_vertice2 = clip_pic(img, region2)\r\n",
        "  iou = IOU(proposal_vertice1, proposal_vertice2)\r\n",
        "\r\n",
        "  return iou"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWG89a_NVkJh"
      },
      "source": [
        "get_IOU usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gDzh6CTVSdM"
      },
      "source": [
        "img_path = f'./17flowers/jpg/7/image_0563.jpg'\r\n",
        "img = skimage.io.imread(img_path)\r\n",
        "iou = get_IOU(img,results[0],results[1])\r\n",
        "print(iou)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTjx-iWmVoAd"
      },
      "source": [
        "Bound-boxs & confidence scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHBc46y4Q-xD"
      },
      "source": [
        "print(results)\r\n",
        "print(conf_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eym46CP0Vz3p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}