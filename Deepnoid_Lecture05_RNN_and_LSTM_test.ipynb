{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deepnoid_Lecture05_RNN_and_LSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMv73vGJ/8z1pl7jmLLCt0o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pyeonseohee/Deeplearning/blob/main/Deepnoid_Lecture05_RNN_and_LSTM_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd_-1cKIyj0b"
      },
      "source": [
        "# Simple RNN, LSTM으로 Time Series data 다루기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF-d3wZDv41a"
      },
      "source": [
        "# Window 혹은 권한이 없는 Linux 계정의 경우 GPU memory를 pull하는데에 문제가 발생하는 경우가 종종 발생한다.\r\n",
        "# 이를 해결하기 위해 GPU 유무를 체크하고 GPU가 있으면 해당 GPU의 memory 공간을 확보하는 코드\r\n",
        "import sys\r\n",
        "import numpy as np\r\n",
        "import sklearn\r\n",
        "import tensorflow as ft\r\n",
        "from tensorflow import keras\r\n",
        "import os\r\n",
        "from pathlib import Path\r\n",
        "import matplotlib as mpl\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "## For Windows only\r\n",
        "## Allow GPU MEMORY GROWTH\r\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\r\n",
        "if gpus:\r\n",
        "  try:\r\n",
        "    # Currently, memory growth needs to be the same across GPUs\r\n",
        "    for gpu in gpus:\r\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\r\n",
        "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\r\n",
        "    pritn(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\r\n",
        "  except RuntimeError as e:\r\n",
        "    # Memory growth must be set before GPUs have been initialized\r\n",
        "    print(e)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIuKAGDsyjRT"
      },
      "source": [
        "sin 함수를 기반으로 간단한 단변량 시계열 데이터를 생성해주는 함수와 해당 함수를 사용해서 데이터를 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3CryU8Qyh1E"
      },
      "source": [
        "# generate time series data function\r\n",
        "\r\n",
        "def generate_time_series(batch_size, n_steps):\r\n",
        "  freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\r\n",
        "  time = np.linspace(0, 1, n_steps)\r\n",
        "  series = 0.5 * np.sin((time - offsets1) * (freq1 * 10 + 10)) # wave 1\r\n",
        "  series +=0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20)) # wave 2\r\n",
        "  series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5) # + noise\r\n",
        "  return series[..., np.newaxis].astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a80PEm0i0M8Q"
      },
      "source": [
        "# generate data\r\n",
        "\r\n",
        "np.random.seed(42)\r\n",
        "n_steps = 50\r\n",
        "series = generate_time_series(10000, n_steps + 1)\r\n",
        "x_train, y_train = series[:7000, :n_steps], series[:7000, -1]\r\n",
        "x_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\r\n",
        "x_test, y_test = series[9000:, :n_steps], series[9000:, -1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ0Qmv4C1rNQ"
      },
      "source": [
        "생성한 시계열 데이터를 그래프로 시각화 해주는 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Beg3wCNW1u9B"
      },
      "source": [
        "# plot dataset\r\n",
        "def plot_series(series, y = None, y_pred = None, x_labels = \"$t$\", y_label = \"$x(t)$\"):\r\n",
        "  plt.plot(series, \".-\")\r\n",
        "  if y is not None:\r\n",
        "    plt.plot(n_steps, y, \"bx\", markersize = 10)\r\n",
        "  if y_pred is not None:\r\n",
        "    plt.plot(n_steps, y_pred, \"ro\")\r\n",
        "  plt.grid(True)\r\n",
        "  if x_label:\r\n",
        "    plt.xlabel(x_label, fontsize = 16)\r\n",
        "  if y_label:\r\n",
        "    plt.ylabel(y_label, fontsize = 16, rotation = 0)\r\n",
        "  plt.hlines(0, 0, 100, linewidth = 1)\r\n",
        "  plt.axis([0, n_steps + 1, -1, 1])\r\n",
        "fig, axes = plt.subplots(nrows = 1, ncols = 3, sharey = True, figsize = (12, 4))\r\n",
        "for col in range(3):\r\n",
        "  plt.sca(axes[col])\r\n",
        "  plot_series(X_valid[col, :, 0], y_valid[col, 0],\r\n",
        "              y_label = (\"$x(t)$\" if col == 0 else None))\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZFIUL6b37C6"
      },
      "source": [
        "데이터의 순서를 특징 시드 순서로 고정( 데이터가 섞이고 순서가 바뀌는 것을 방지)\r\n",
        "\r\n",
        "단순 Fully Connected Layer를 통해 20 epoch 동안 학습 수행\r\n",
        "\r\n",
        "해달 모델로 forecasting 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfvxxoHP4HxS"
      },
      "source": [
        "np.random.seed(42)\r\n",
        "tf.random.set_seed(42)\r\n",
        "\r\n",
        "# linear prediction model build\r\n",
        "model = keras.models.Sequential([keras.layers.Flatten(input_shape = [50, 1]),\r\n",
        "                                 keras.layers.Dense(1)])\r\n",
        "model.compile(loss = \"mse\", optimizer = \"adam\")\r\n",
        "\r\n",
        "#model train\r\n",
        "history = model.fit(X_train, y_train, epochs = 20,\r\n",
        "                    validation_data = (X_valid, y_valid))\r\n",
        "# model validation\r\n",
        "model.evaluate(X_valid, y_valid)\r\n",
        "\r\n",
        "# model prediction\r\n",
        "y_pred = model.predict(X_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5HeUT245gSv"
      },
      "source": [
        "학습 결과 오프젝트에서 loss 수치를 획득하고 이를 사용해서 x축은 epoch, y축은 loss로 그래프를 그려 loss의 변화를 시각화하는 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lU0wdTFf5p2-"
      },
      "source": [
        "# plot learning curve\r\n",
        "def plot_learning_curver(loss, val_loss):\r\n",
        "  plt.plot(np.arange(len(loss)) + 0.5, loss, \"b.-\", label = \"Training loss\")\r\n",
        "  plt.plot(np.arange(len(val_loss)) + 1, val_loss, \"r.-\", label = \"Validation loss\")\r\n",
        "  plt.gca().xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer = True))\r\n",
        "  plt.axis([1, 20, 0, 0.05])\r\n",
        "  plt.legend(fontsize = 14)\r\n",
        "  plt.xlabel(\"Epochs\")\r\n",
        "  plt.ylabel(\"Loss\")\r\n",
        "  plt.grid(True)\r\n",
        "\r\n",
        "plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])\r\n",
        "plt.show()\r\n",
        "\r\n",
        "#plot prediction result\r\n",
        "plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0,0])\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAO_HDq36vDf"
      },
      "source": [
        "FClayer 대신 RNN cell 1개를 써서 같은 데이터를 학습하고 loss 변화를 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLEILcso63go"
      },
      "source": [
        "# Using Vanilla RNN\r\n",
        "np.random.seed(42)\r\n",
        "tf.random.set_seed(42)\r\n",
        "\r\n",
        "model = keras.models.Sequential([keras.layers.SimpleRNN(1, input_shape = [None,1])])\r\n",
        "optimizer = keras.optimizers.Adam(lr = 0.005)\r\n",
        "model.compile(loss = \"mse\", optimizer = optimizer)\r\n",
        "\r\n",
        "# model train\r\n",
        "history = model.fit(X_train, y_train, epochs =20,\r\n",
        "                    validation_data = (X_valid, y_valid))\r\n",
        "# model validation\r\n",
        "model.evaulate(X_valid, y_valid)\r\n",
        "\r\n",
        "# model prediction\r\n",
        "y_pred = model.predict(X_valid)\r\n",
        "\r\n",
        "# plot learning curve\r\n",
        "plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])\r\n",
        "plt.show()\r\n",
        "\r\n",
        "#plot prediction result\r\n",
        "plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIog04ax7_fy"
      },
      "source": [
        "RNN cell을 여러층 쌓아서 깊은 RNN 구조를 만들고 같은 데이터를 학습하고 loss 변화를 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeGEbwzW8FyH"
      },
      "source": [
        "# Using Deep RNN\r\n",
        "np.random.seed(42)\r\n",
        "tf.random.set_seed(42)\r\n",
        "\r\n",
        "model = keras.models.Sequential([keras.layers.SimpleRNN(20, return_sequences = True, input_shape = [None, 1]),\r\n",
        "                                 keras.layers.SimpleRNN(20, return_sequences = True),\r\n",
        "                                 keras.layers.SimpleRNN(1)])\r\n",
        "model.compile(loss = \"mse\", optimizer = \"adam\")\r\n",
        "\r\n",
        "# model train\r\n",
        "history = model.fit(X_train, y_train, epochs = 20,\r\n",
        "                    validation_data = (X_valid, y_valid))\r\n",
        "# model validation\r\n",
        "model.evaluate(X_valid, y_valid)\r\n",
        "\r\n",
        "# model prediction\r\n",
        "y_pred = model.predict(X_valid)\r\n",
        "\r\n",
        "# plot learning curve\r\n",
        "plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])\r\n",
        "plt.show()\r\n",
        "\r\n",
        "#plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKclNh9W9dTY"
      },
      "source": [
        "RNN cell을 여러층 쌓아서 깊은 RNN 구조를 만들고 마지막에 FC 레이어를 통해 RNN에서 생성된 feature를 학습하여 forecasting 핟록 만든 신경망으로 같은 데이터를 학습하고 loss변화를 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TemHOXNh9qS1"
      },
      "source": [
        "# Using Deep RNN with DNN\r\n",
        "np.random.seed(42)\r\n",
        "tf.random.set_seed(42)\r\n",
        "\r\n",
        "model = keras.models.Sequential([keras.layers.SimpleRNN(20, return_sequences = True, input_shape = [None, 1]),\r\n",
        "                                 keras.layers.SimpleRNN(20),\r\n",
        "                                 keras.layers.Dense(1)])\r\n",
        "model.compile(loss = \"mse\", optimizer = \"adam\")\r\n",
        "history = model.fit(X_train, y_train, epochs = 20,\r\n",
        "                    validation_data = (X_valid, y_valid))\r\n",
        "# model validation\r\n",
        "model.evaluate(X_valid, y_valid)\r\n",
        "\r\n",
        "# model prediction\r\n",
        "y_pred = model.predict(X_valid)\r\n",
        "\r\n",
        "# plot learning curve\r\n",
        "plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# plot prediction result\r\n",
        "plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAPYsChe_ZKs"
      },
      "source": [
        "이제 한 시점(step)이 아닌 여러 시점을 forecast함.\r\n",
        "\r\n",
        "우선 이전에 학습했던 모델을 사용해서 1시점씩 10번 예측하여 10시점의 예측 결과를 만들고 해당 결과를 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7UFqmyE_iVp"
      },
      "source": [
        "# Forecasting several steps\r\n",
        "# forecast 10 step by predicting 1 step that iterate 10 times.\r\n",
        "np.random.seed(43) # not 42, as it would give the first series in the train set\r\n",
        "\r\n",
        "series = generate_time_series(1, n_steps + 10)\r\n",
        "X_new, Y_new = series[:, :n_steps], series[:, n_steps:]\r\n",
        "X = X_new\r\n",
        "for step_ahead in range(10):\r\n",
        "  y_pred_one = model.predict(X[:, step_ahead:])[:, np.newaxis, :]\r\n",
        "  X = np.concatenate([X, y_pred_one], axis = 1)\r\n",
        "\r\n",
        "Y_pred = X[:, n_steps:]\r\n",
        "\r\n",
        "def plot_multiple_forecasts(X, Y, Y_pred):\r\n",
        "  n_steps = X.shape[1]\r\n",
        "  ahead = Y.shape[1]\r\n",
        "  plot_series(X[0, :, 0])\r\n",
        "  plt.plot(np.arange(n_steps, n_steps + ahead), Y[0, :, 0], \"ro-\", label = \"Actual\")\r\n",
        "  plt.plot(np.arrange(n_steps, n_steps + ahead), Y_pred[0, :, 0], \"bx-\", label = \"Forecast\", markersize = 10)\r\n",
        "  plt.axis([0, n_steps + ahead, -1, 1])\r\n",
        "  plt.legend(fontsize = 14)\r\n",
        "\r\n",
        "plot_multiple_forecasts(X_new, Y_new, Y_pred)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvLssGHrDt-b"
      },
      "source": [
        "10시점을 한 번에 예측하기 위한 새로운 데이터 셋을 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mEjmIweDygC"
      },
      "source": [
        "# Build new dataset for forecast 10 step at onse\r\n",
        "\r\n",
        "np.random.seed(42)\r\n",
        "n_steps = 50\r\n",
        "series = generate_time_series(10000, n_steps + 10)\r\n",
        "X_train = series[:7000, :n_steps]\r\n",
        "X_valid = series[7000:9000, :n_steps]\r\n",
        "X_test = series[9000:, :n_steps]\r\n",
        "Y = np.empty((10000, n_steps, 10))\r\n",
        "for step_ahead in range(1, 10 + 1):\r\n",
        "  Y[..., step_ahead - 1] = series[..., step_ahead:step_ahead + n_steps, 0]\r\n",
        "\r\n",
        "Y_train = Y[:7000]\r\n",
        "Y_valid = Y[7000:9000]\r\n",
        "Y_test = Y[9000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RElwK2xqEnrd"
      },
      "source": [
        "RNN cell을 여러층 쌓아 Deep RNN을 만들고 마지막층의 FClayer을 keras.layers.TimeDistributed로 감싼다. FClayer을 감싼 이유는?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvPdNAfzE2gT"
      },
      "source": [
        "#forecast 10 step at once by using deep RNN\r\n",
        "np.random.seed(42)\r\n",
        "tf.random.set_seed(42)\r\n",
        "\r\n",
        "model = keras.models.Sequential([keras.layers.SimpleRNN(20, return_sequences = True, input_shape= [None, 1]),\r\n",
        "                                 keras.layers.SimpleRNN(20, return_sequences = True),\r\n",
        "                                 keras.layers.TimeDistributed(keras.layers.Dense(10))])\r\n",
        "\r\n",
        "def last_time_step_mse(Y_true, T_pred):\r\n",
        "  return keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])\r\n",
        "\r\n",
        "model.compile(loss = \"mse\", optimizer = keras.optimizers.Adam(lr = 0.01), metrics = [last_time_step_mse])\r\n",
        "history = model.fit(X_train, Y_train, epochs = 20,\r\n",
        "                    validation_data = (X_valid, Y_valid))\r\n",
        "\r\n",
        "np.random.seed(43)\r\n",
        "\r\n",
        "series = generate_time_series(1, 50 + 10)\r\n",
        "X_new, Y_new = series[:, :50, :], series[:, 50:, :]\r\n",
        "Y_pred = model.predict(X_new)[:, -1][..., np.newaxis]\r\n",
        "\r\n",
        "plot_multiple_forecasts(X_new, Y_nex, Y_pred)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVgx7t7aGel1"
      },
      "source": [
        "keras에서의 custom metric 사용-> last_time_step_mse():\r\n",
        "\r\n",
        "마지막 타임 스텝에서의 Ground truth와 prediction으로 MSE를 계산하는 함수\r\n",
        "\r\n",
        "Y_true와 Y_Pred를 입력받고 keras 함수로 MSE를 계산한 다음 이를 keras에 내장된 epoch별 상태 출력함수에 추가함.\r\n",
        "\r\n",
        "model을 compile해서 build할 때 함수를 추가해주면 매 epoch마다 동작하는 방식"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB3Bf3yhG6ZR"
      },
      "source": [
        "# forecast 10 steps at once by using deep RNN\r\n",
        "\r\n",
        "np.random.seed(42)\r\n",
        "tf.random.set_model(42)\r\n",
        "\r\n",
        "model = keras.models.Sequential([keras.layers.SimpleRNN(20, return_sequences = True, input_shape = [None, 1]),\r\n",
        "                                 keras.layers.SimpleRNN(20, return_sequences = True),\r\n",
        "                                 keras.layers.TimeDistributed(keras.layers.Dense(10))])\r\n",
        "\r\n",
        "def last_time_step_mse(Y_true, Y_pred):\r\n",
        "  return keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])\r\n",
        "\r\n",
        "model.compile(loss = \"mse\", optimizer = keras.optimizers.Adam(lr = 0.01), metrics = [last_time_step_mse])\r\n",
        "history = model.fot(X_train, Y_train, spochs = 20,\r\n",
        "                    validation_data = (X_valid, Y_valid))\r\n",
        "np.random.seed(43)\r\n",
        "\r\n",
        "series = generate_time_series(1, 50 + 10)\r\n",
        "X_new, Y_new = series[:, :50, :], series[:, 50:, :]\r\n",
        "Y_pred = model.predict(X_new)[:, -1][..., np.newaxis]\r\n",
        "\r\n",
        "plot_multiple_forecasts(X_new, Y_new, Y_pred)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzKEHVW5Itoe"
      },
      "source": [
        "10 step model을 사용해서 학습하고 한 번에 10 step 예측한 결과"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkrgLzH5I1__"
      },
      "source": [
        "np.random.seed(42)\r\n",
        "tf.random.set_seed(42)\r\n",
        "\r\n",
        "model = keras.models.Sequential([keras.layers.SimpleRNN(20, return_sequence = True, input_shape = [None, 1]),\r\n",
        "                                 keras.layers.SimpleRNN(20, return_sequential = True),\r\n",
        "                                 keras.layers.TimeDistributed(keras.layers.Dense(10))])\r\n",
        "\r\n",
        "def last_time_step_mse(Y_true, Y_pred):\r\n",
        "  return keras.metrics.mean_squared_error(Y_ture[:, -1], Y_pred[:, -1])\r\n",
        "\r\n",
        "model.compile(loss = \"mse\", optimizer = keras.optimizers.Adam(lr = 0.01), metrics = [last_time_step_mse])\r\n",
        "history = model.fit(X_train, Y_train, epochs = 20,\r\n",
        "                    validation_data = (X_valid, Y_valid))\r\n",
        "np.random.seed(43)\r\n",
        "\r\n",
        "series = generate_time_series(1, 50 + 10)\r\n",
        "X_new, Y_new = series[:, :50, :], series[:, 50:, :]\r\n",
        "Y_pred = model.predict(X_new)[:, -1][..., np.newaxis]\r\n",
        "\r\n",
        "plot_multiple_forecasts(X_new, Y_new, Y_pred)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGz3gspWK4Bo"
      },
      "source": [
        "Vanila RNN cell을 LSTM으로 바꾼 뒤 동일한 데이터셋으로 10step 학습 모델 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5vyQcoDLC9L"
      },
      "source": [
        "# Deep RNN with DNN using LSTM cell for forecasting next 10 step at each time step\r\n",
        "np.random.seed(42)\r\n",
        "tf.random.set_seed(42)\r\n",
        "\r\n",
        "model = keras.models.Sequential([keras.layers.LSTM(20, return_sequences = True, input_shape = [None, 1]),\r\n",
        "                                 keras.layers.LSTM(20, return_sequences = True),\r\n",
        "                                 keras.layers.TimeDistributed(keras.layers.Dense(10))])\r\n",
        "model.compile(loss = \"mse\", optimizer = \"adam\", metrics = [last_time_step_mse])\r\n",
        "history - model.fit(X_train, Y_train, epochs = 20,\r\n",
        "                    validation_data = (X_valid, Y_valid))\r\n",
        "\r\n",
        "model.evaluate(X_valid, Y_valid)\r\n",
        "\r\n",
        "plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])\r\n",
        "plt.show()\r\n",
        "\r\n",
        "np.random.seed(43)\r\n",
        "\r\n",
        "series = generate_time_series(1, 50+10)\r\n",
        "X_new, Y_new = series[:, :50, :], series[:, 50:, :]\r\n",
        "Y_pred = model.predict(X_new)[:, -1][..., np.newaxis]\r\n",
        "\r\n",
        "plot_multiple_forecasts(X_new, Y_new, Y_pred)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}